{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install spacy\n",
    "# !{sys.executable} -m spacy download en\n",
    "# import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from IPython.display import Markdown, display, display_html, HTML\n",
    "\n",
    "def printmd(string, color=None):\n",
    "    if color != None:\n",
    "        string = \"<span style='color:{}'>{}</span>\".format(color, string)\n",
    "    display(Markdown(string))    \n",
    "\n",
    "def print_bold(string, color=None):\n",
    "    printmd(\"**{}**\".format(string), color)\n",
    "    \n",
    "def print_italic(string, color=None):\n",
    "    printmd(\"*{}*\".format(string), color)\n",
    "    \n",
    "def print_header(string):\n",
    "    printmd(\"### {}\".format(string))\n",
    "\n",
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str += df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline;margin-right: 10px;\"'),raw=True)\n",
    "\n",
    "def print_df(df):\n",
    "    display_side_by_side(df)\n",
    "    \n",
    "# printmd('__bold__')\n",
    "# print_bold('bold')\n",
    "# print_header('print_header')\n",
    "# print_italic('italic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "def _sizeof_fmt(elem):\n",
    "    elem = list(elem)\n",
    "    elem[1] = sizeof_fmt(elem[1])\n",
    "    return elem\n",
    "\n",
    "\n",
    "def print_mem_usage_vars(_dir):\n",
    "    # These are the usual ipython objects, including this one you are creating\n",
    "    ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "    mem_usage = [(x, sys.getsizeof(globals().get(x))) for x in _dir if not x.startswith('_') and x not in sys.modules and x not in ipython_vars]\n",
    "    mem_usage = sorted(mem_usage, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    pprint(list(map(_sizeof_fmt, mem_usage[:10])))\n",
    "\n",
    "# print_mem_usage_vars(dir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка и изучение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated(subset=['text'], keep=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего: 159571, токсичных 16225 (10.17%), не токсичных 143346\n"
     ]
    }
   ],
   "source": [
    "def print_class_balance(data):\n",
    "    cnt_total = data.shape[0]\n",
    "    cnt_toxic = data[data['toxic'] == 1]['toxic'].count()\n",
    "    cnt_not_toxic = data[data['toxic'] == 0]['toxic'].count()\n",
    "    prc_toxic = round((cnt_toxic*100)/cnt_total,2)\n",
    "\n",
    "    print('Всего: {}, токсичных {} ({}%), не токсичных {}'.format(\n",
    "        cnt_total,\n",
    "        cnt_toxic,\n",
    "        prc_toxic,\n",
    "        cnt_not_toxic\n",
    "    ))\n",
    "    \n",
    "print_class_balance(data)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего: 159571, токсичных 16225 (10.17%), не токсичных 143346\n",
    "\n",
    "* Датасет несбалансирован\n",
    "* Содержит только английские фразы\n",
    "* Дубликатов нет\n",
    "* Пустых строк нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = SnowballStemmer(\"english\")\n",
    "\n",
    "def lemmatize(sentence):\n",
    "    return ' '.join([stem.stem(w) for w in nltk.word_tokenize(sentence)])\n",
    "\n",
    "def clear_text(text):\n",
    "    return \" \".join(re.sub(r'[^A-Za-z`\\' ]', ' ', text).split())\n",
    "\n",
    "def text_process(sentence):\n",
    "    return lemmatize(clear_text(sentence))\n",
    "\n",
    "# test\n",
    "# sentence = data.iloc[0]['text']\n",
    "# print(sentence)\n",
    "# print('--')\n",
    "# print(text_process(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# def lemmatize2(sentence):\n",
    "#     return ' '.join([token.lemma_ for token in nlp(sentence)])\n",
    "\n",
    "# def text_process2(sentence):\n",
    "#     return lemmatize2(clear_text(sentence))\n",
    "\n",
    "# test2\n",
    "# sentence = data.iloc[0]['text']\n",
    "# print(sentence)\n",
    "# print('--')\n",
    "# print(text_process2(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "#\n",
    "# Using SnowballStemmer\n",
    "#\n",
    "\n",
    "# data['lemm_text'] = data['text'].apply(\n",
    "#     lambda x: text_process(x)\n",
    "# )\n",
    "# data.to_csv(r'toxic_comments_lemmatized.csv', index = False)\n",
    "\n",
    "# # CPU times: user 4min 4s, sys: 360 ms, total: 4min 4s\n",
    "# # Wall time: 4min 7s\n",
    "\n",
    "data = pd.read_csv('toxic_comments_lemmatized.csv')[['lemm_text', 'toxic']]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "#\n",
    "# Using spacy\n",
    "#\n",
    "\n",
    "# data['lemm_text'] = data['text'].apply(\n",
    "#     lambda x: text_process2(x)\n",
    "# )\n",
    "# data.to_csv(r'toxic_comments_lemmatized2.csv', index = False)\n",
    "\n",
    "# CPU times: user 15min 34s, sys: 1.56 s, total: 15min 36s\n",
    "# Wall time: 15min 53s\n",
    "\n",
    "# data = pd.read_csv('toxic_comments_lemmatized2.csv')[['lemm_text', 'toxic']]\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lemm_text    6\n",
       "toxic        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При подготовке текста\n",
    "\n",
    "* Удалил все символы по маске r'[^A-Za-z`\\' ]'\n",
    "* Использовал SnowballStemmer, хотя очень хотелось nltk wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Sample**\n",
      "bat\n",
      "foot\n",
      "edits\n",
      "voted\n",
      "driving\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# sentence = data.iloc[0]['text']\n",
    "# sentence = clear_text(sentence) \n",
    "# word_list = nltk.word_tokenize(sentence)\n",
    "# lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "# lemmatized_output = ' '.join([wordnet.synsets(w) for w in word_list])\n",
    "#     return lemmatized_output\n",
    "# print('**Source**')\n",
    "# print(sentence)\n",
    "# print()\n",
    "# print('**lematized**')\n",
    "# print(lemmatized_output)\n",
    "# print()\n",
    "\n",
    "print('**Sample**')\n",
    "print(lemmatizer.lemmatize(\"bats\"))\n",
    "print(lemmatizer.lemmatize(\"feet\"))\n",
    "print(lemmatizer.lemmatize(\"edits\"))\n",
    "print(lemmatizer.lemmatize(\"voted\"))\n",
    "print(lemmatizer.lemmatize(\"driving\"))\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=maroon>\n",
    "По словам bats, feet я вижу что как-то оно работает, но дальше я ожидаю преобразования\n",
    "\n",
    "* edits -> edit\n",
    "* voted -> vote\n",
    "* driving -> drive\n",
    "\n",
    "А этого не происходит\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>Да, чтобы не возникало ошибок, надо корректно задавать части речи для слов, см. ссылку https://stackoverflow.com/questions/32957895/wordnetlemmatizer-not-returning-the-right-lemma-unless-pos-is-explicit-python  </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_upsampling(df):\n",
    "    df_majority = df[df.toxic==0]\n",
    "    df_minority = df[df.toxic==1]\n",
    "    n_samples = df_majority.shape[0]\n",
    "\n",
    "    df_minority_upsampled = resample(df_minority, \n",
    "                                     replace=True,     # sample with replacement\n",
    "                                     n_samples=n_samples,    # to match majority class\n",
    "                                     random_state=42) # reproducible results\n",
    "\n",
    "    df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "    print_class_balance(df_upsampled)\n",
    "    return df_upsampled\n",
    "\n",
    "\n",
    "def do_downsampling(df):\n",
    "    df_majority = df[df.toxic==0]\n",
    "    df_minority = df[df.toxic==1]\n",
    "    n_samples = df_minority.shape[0]\n",
    "\n",
    "    df_majority_downsampled = resample(df_majority, \n",
    "                                     replace=False,    # sample without replacement\n",
    "                                     n_samples=n_samples,     # to match minority class\n",
    "                                     random_state=42) # reproducible results\n",
    "\n",
    "\n",
    "    df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "    print_class_balance(df_downsampled)\n",
    "    return df_downsampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_idf(df_train, df_test):\n",
    "#     corpus_train = df_train['lemm_text'].values.astype('U')\n",
    "#     corpus_test = df_test['lemm_text'].values.astype('U')\n",
    "    corpus_train = df_train['lemm_text'].apply(lambda x: np.str_(x))\n",
    "    corpus_test = df_test['lemm_text'].apply(lambda x: np.str_(x))\n",
    "\n",
    "    \n",
    "    # nltk.download('stopwords')\n",
    "    stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "    tf_idf_model = TfidfVectorizer(\n",
    "        min_df=5, max_df=0.7, stop_words=stopwords\n",
    "    )\n",
    "\n",
    "    tf_idf_model.fit(corpus_train)\n",
    "    tf_idf_train = tf_idf_model.transform(corpus_train)\n",
    "    tf_idf_test = tf_idf_model.transform(corpus_test)\n",
    "\n",
    "    print(\"Размер матрицы train:\", tf_idf_train.shape, 'test:', tf_idf_test.shape)\n",
    "    return (tf_idf_train, tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commit_result(nick, y_train, y_pred_train, y_test, y_pred_test):\n",
    "    f1_score_train =  f1_score(y_train, y_pred_train)\n",
    "    f1_score_test = f1_score(y_test, y_pred_test)\n",
    "    print(nick)\n",
    "    print('train f1_score', f1_score_train)\n",
    "    print('test f1_score', f1_score_test)\n",
    "\n",
    "    return (f1_score_train, f1_score_test)\n",
    "\n",
    "# test\n",
    "# commit_result('test', [1, 0], [1, 0], [1, 0], [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_result_init():\n",
    "    return pd.DataFrame(columns=['nick', 'f1_train', 'f1_test'])\n",
    "\n",
    "def df_result_add(df_result, nick, f1_train, f1_test):\n",
    "    return df_result.append(\n",
    "        {'nick': nick, 'f1_train': f1_train, 'f1_test': f1_test}, \n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "df_result = df_result_init().copy()\n",
    "\n",
    "# test\n",
    "# commit_result(nick, y_train, y_pred_train, y_test, y_pred_test)\n",
    "# f1_train, f1_test = commit_result('test', [1, 0], [1, 0], [1, 0], [1, 0])\n",
    "# df_result = df_result_add(df_result, 'test', f1_train, f1_test)\n",
    "# df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_full, data_valid = train_test_split(\n",
    "    data, test_size = 0.1, random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "*Баланс классов обучающего набора*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего: 143613, токсичных 14650 (10.2%), не токсичных 128963\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "*Баланс классов валидационного набора*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего: 15958, токсичных 1575 (9.87%), не токсичных 14383\n"
     ]
    }
   ],
   "source": [
    "print_italic('Баланс классов обучающего набора')\n",
    "print_class_balance(data_train_full)\n",
    "\n",
    "print_italic('Баланс классов валидационного набора')\n",
    "print_class_balance(data_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "*Создание датафрейма с балансированными классами*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "* Я взял полные тренировочные данные\n",
       "* Сделал на базе него датасет где присутствуют все данные toxic==1 и столько же строк toxic==1\n",
       "* Результирующий датасет перемешал\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего: 29300, токсичных 14650 (50.0%), не токсичных 14650\n"
     ]
    }
   ],
   "source": [
    "print_italic('Создание датафрейма с балансированными классами')\n",
    "printmd(\n",
    "    \"* Я взял полные тренировочные данные\\n\"+\n",
    "    \"* Сделал на базе него датасет где присутствуют все данные toxic==1 и столько же строк toxic==1\\n\"+\n",
    "    \"* Результирующий датасет перемешал\\n\"\n",
    ")\n",
    "\n",
    "df_c1 = data_train_full[data_train_full['toxic']==1]\n",
    "df_c0 = data_train_full[data_train_full['toxic']==0]\n",
    "\n",
    "c1_cnt = df_c1.shape[0]\n",
    "\n",
    "df_c0_balanced = df_c0.sample(c1_cnt, random_state=42)\n",
    "data_train_balanced = pd.concat([df_c1, df_c0_balanced])\n",
    "data_train_balanced = data_train_balanced.sample(frac=1)\n",
    "\n",
    "print_class_balance(data_train_balanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "*Сэмпл данных 10000 строк*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего: 10000, токсичных 1014 (10.14%), не токсичных 8986\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "*Сэмпл данных 10000 строк (сбалансированных)*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего: 10000, токсичных 4966 (49.66%), не токсичных 5034\n"
     ]
    }
   ],
   "source": [
    "data_smp10k = data_train_full.sample(10000, random_state=42).copy()\n",
    "data_smp10k_balanced = data_train_balanced.sample(10000, random_state=42).copy()\n",
    "\n",
    "print_italic('Сэмпл данных 10000 строк')\n",
    "print_class_balance(data_smp10k)\n",
    "\n",
    "print_italic('Сэмпл данных 10000 строк (сбалансированных)')\n",
    "print_class_balance(data_smp10k_balanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы train: (9000, 4468) test: (1000, 4468)\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(\n",
    "    data_smp10k, test_size = 0.1, random_state = 42\n",
    ")\n",
    "\n",
    "(X_train, X_test) = create_tf_idf(data_train, data_test)\n",
    "\n",
    "y_train = data_train['toxic']\n",
    "y_test = data_test['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression origin\n",
      "train f1_score 0.8539651837524178\n",
      "test f1_score 0.7079646017699114\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nick</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression origin</td>\n",
       "      <td>0.853965</td>\n",
       "      <td>0.707965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        nick  f1_train   f1_test\n",
       "0  LogisticRegression origin  0.853965  0.707965"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight='balanced', solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "nick = 'LogisticRegression origin'\n",
    "f1_train, f1_test = commit_result(nick, y_train, y_pred_train, y_test, y_pred_test)\n",
    "result.append({\n",
    "    'nick':nick, 'train_size':X_train.shape[0], 'test_size':X_test.shape[0],\n",
    "    'f1_train':f1_train, 'f1_test':f1_test}\n",
    ")\n",
    "df_result = df_result_add(df_result, nick, f1_train, f1_test)\n",
    "df_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы train: (9000, 4254) test: (1000, 4254)\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(\n",
    "    data_smp10k_balanced, test_size = 0.1, random_state = 42\n",
    ")\n",
    "\n",
    "(X_train, X_test) = create_tf_idf(data_train, data_test)\n",
    "\n",
    "y_train = data_train['toxic']\n",
    "y_test = data_test['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression balanced full\n",
      "train f1_score 0.9261929282526604\n",
      "test f1_score 0.8891213389121339\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nick</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression origin</td>\n",
       "      <td>0.853965</td>\n",
       "      <td>0.707965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression balanced full</td>\n",
       "      <td>0.926193</td>\n",
       "      <td>0.889121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               nick  f1_train   f1_test\n",
       "0         LogisticRegression origin  0.853965  0.707965\n",
       "1  LogisticRegression balanced full  0.926193  0.889121"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight='balanced', solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "nick = 'LogisticRegression balanced full'\n",
    "f1_train, f1_test = commit_result(nick, y_train, y_pred_train, y_test, y_pred_test)\n",
    "result.append({\n",
    "    'nick':nick, 'train_size':X_train.shape[0], 'test_size':X_test.shape[0],\n",
    "    'f1_train':f1_train, 'f1_test':f1_test}\n",
    ")\n",
    "df_result = df_result_add(df_result, nick, f1_train, f1_test)\n",
    "df_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего: 10000, токсичных 1014 (10.14%), не токсичных 8986\n"
     ]
    }
   ],
   "source": [
    "print_class_balance(data_smp10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего: 16194, токсичных 8097 (50.0%), не токсичных 8097\n",
      "Размер матрицы train: (16194, 6620) test: (1000, 6620)\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(\n",
    "    data_smp10k, test_size = 0.1, random_state = 42\n",
    ")\n",
    "\n",
    "data_train_upsampled = do_upsampling(data_train)\n",
    "\n",
    "(X_train, X_test) = create_tf_idf(data_train_upsampled, data_test)\n",
    "\n",
    "y_train = data_train_upsampled['toxic']\n",
    "y_test = data_test['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression upsampling\n",
      "train f1_score 0.9834700624464308\n",
      "test f1_score 0.7053571428571429\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nick</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression origin</td>\n",
       "      <td>0.853965</td>\n",
       "      <td>0.707965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression balanced full</td>\n",
       "      <td>0.926193</td>\n",
       "      <td>0.889121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression upsampling</td>\n",
       "      <td>0.983470</td>\n",
       "      <td>0.705357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               nick  f1_train   f1_test\n",
       "0         LogisticRegression origin  0.853965  0.707965\n",
       "1  LogisticRegression balanced full  0.926193  0.889121\n",
       "2     LogisticRegression upsampling  0.983470  0.705357"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight='balanced', solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "nick = 'LogisticRegression upsampling'\n",
    "f1_train, f1_test = commit_result(nick, y_train, y_pred_train, y_test, y_pred_test)\n",
    "result.append({\n",
    "    'nick':nick, 'train_size':X_train.shape[0], 'test_size':X_test.shape[0],\n",
    "    'f1_train':f1_train, 'f1_test':f1_test}\n",
    ")\n",
    "df_result = df_result_add(df_result, nick, f1_train, f1_test)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего: 1806, токсичных 903 (50.0%), не токсичных 903\n",
      "Размер матрицы train: (1806, 1619) test: (1000, 1619)\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(\n",
    "    data_smp10k, test_size = 0.1, random_state = 42\n",
    ")\n",
    "\n",
    "data_train_downsampling = do_downsampling(data_train)\n",
    "\n",
    "(X_train, X_test) = create_tf_idf(data_train_downsampling, data_test)\n",
    "\n",
    "y_train = data_train_downsampling['toxic']\n",
    "y_test = data_test['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression downsampling\n",
      "train f1_score 0.931830985915493\n",
      "test f1_score 0.6319444444444445\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nick</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression origin</td>\n",
       "      <td>0.853965</td>\n",
       "      <td>0.707965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression balanced full</td>\n",
       "      <td>0.926193</td>\n",
       "      <td>0.889121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression upsampling</td>\n",
       "      <td>0.983470</td>\n",
       "      <td>0.705357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression downsampling</td>\n",
       "      <td>0.931831</td>\n",
       "      <td>0.631944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               nick  f1_train   f1_test\n",
       "0         LogisticRegression origin  0.853965  0.707965\n",
       "1  LogisticRegression balanced full  0.926193  0.889121\n",
       "2     LogisticRegression upsampling  0.983470  0.705357\n",
       "3   LogisticRegression downsampling  0.931831  0.631944"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight='balanced', solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "nick = 'LogisticRegression downsampling'\n",
    "f1_train, f1_test = commit_result(nick, y_train, y_pred_train, y_test, y_pred_test)\n",
    "result.append({\n",
    "    'nick':nick, 'train_size':X_train.shape[0], 'test_size':X_test.shape[0],\n",
    "    'f1_train':f1_train, 'f1_test':f1_test}\n",
    ")\n",
    "df_result = df_result_add(df_result, nick, f1_train, f1_test)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nick</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression origin</td>\n",
       "      <td>0.853965</td>\n",
       "      <td>0.707965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression balanced full</td>\n",
       "      <td>0.926193</td>\n",
       "      <td>0.889121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression upsampling</td>\n",
       "      <td>0.983470</td>\n",
       "      <td>0.705357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression downsampling</td>\n",
       "      <td>0.931831</td>\n",
       "      <td>0.631944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               nick  f1_train   f1_test\n",
       "0         LogisticRegression origin  0.853965  0.707965\n",
       "1  LogisticRegression balanced full  0.926193  0.889121\n",
       "2     LogisticRegression upsampling  0.983470  0.705357\n",
       "3   LogisticRegression downsampling  0.931831  0.631944"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression origin\n",
      "f1_train 0.8539651837524178\n",
      "f1_test 0.7079646017699114\n",
      "train_size 9000\n",
      "test_size 1000\n",
      "\n",
      "LogisticRegression balanced full\n",
      "f1_train 0.9261929282526604\n",
      "f1_test 0.8891213389121339\n",
      "train_size 9000\n",
      "test_size 1000\n",
      "\n",
      "LogisticRegression upsampling\n",
      "f1_train 0.9834700624464308\n",
      "f1_test 0.7053571428571429\n",
      "train_size 16194\n",
      "test_size 1000\n",
      "\n",
      "LogisticRegression downsampling\n",
      "f1_train 0.931830985915493\n",
      "f1_test 0.6319444444444445\n",
      "train_size 1806\n",
      "test_size 1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in result:\n",
    "    print(row['nick'])\n",
    "    print('f1_train', row['f1_train'])\n",
    "    print('f1_test', row['f1_test'])\n",
    "    print('train_size', row['train_size'])\n",
    "    print('test_size', row['test_size'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### На семпле данных в 10000 строк получились следующие результаты\n",
    "\n",
    "LogisticRegression origin\n",
    "* f1_train 0.8539651837524178\n",
    "* f1_test 0.7079646017699114\n",
    "* train_size 9000\n",
    "* test_size 1000\n",
    "\n",
    "LogisticRegression upsampling\n",
    "* f1_train 0.9834700624464308\n",
    "* f1_test 0.7053571428571429\n",
    "* train_size 16194\n",
    "* test_size 1000\n",
    "\n",
    "LogisticRegression downsampling\n",
    "* f1_train 0.931830985915493\n",
    "* f1_test 0.6319444444444445\n",
    "* train_size 1806\n",
    "* test_size 1000\n",
    "\n",
    "\n",
    "#### Сбалансированный датасет\n",
    "* Я взял полные тренировочные данные\n",
    "* Сделал на базе него датасет где присутствуют все данные toxic==1 и столько же строк toxic==1\n",
    "* Результирующий датасет перемешал\n",
    "\n",
    "LogisticRegression balanced full\n",
    "* f1_train 0.9288389513108614\n",
    "* f1_test 0.8617363344051446\n",
    "* train_size 9000\n",
    "* test_size 1000\n",
    "\n",
    "\n",
    "\n",
    "Для обучения я использовал гиперпараметр class_weight='balanced'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_final = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression full balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего: 29300, токсичных 14650 (50.0%), не токсичных 14650\n"
     ]
    }
   ],
   "source": [
    "print_class_balance(data_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы train: (29300, 8600) test: (15958, 8600)\n",
      "CPU times: user 5.84 s, sys: 64 ms, total: 5.91 s\n",
      "Wall time: 6.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "(X_train, X_test) = create_tf_idf(data_train_balanced, data_valid)\n",
    "\n",
    "y_train = data_train_balanced['toxic']\n",
    "y_test = data_valid['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression full balanced\n",
      "train f1_score 0.9264588050862219\n",
      "test f1_score 0.6862213458220361\n",
      "CPU times: user 484 ms, sys: 4 ms, total: 488 ms\n",
      "Wall time: 495 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "nick = 'LogisticRegression full balanced'\n",
    "f1_train, f1_test = commit_result(nick, y_train, y_pred_train, y_test, y_pred_test)\n",
    "result_final.append({\n",
    "    'nick':nick, 'train_size':X_train.shape[0], 'test_size':X_test.shape[0],\n",
    "    'f1_train':f1_train, 'f1_test':f1_test}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего: 143613, токсичных 14650 (10.2%), не токсичных 128963\n"
     ]
    }
   ],
   "source": [
    "print_class_balance(data_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы train: (143613, 23047) test: (15958, 23047)\n",
      "CPU times: user 21 s, sys: 300 ms, total: 21.3 s\n",
      "Wall time: 21.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "(X_train, X_test) = create_tf_idf(data_train_full, data_valid)\n",
    "\n",
    "y_train = data_train_full['toxic']\n",
    "y_test = data_valid['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression full\n",
      "train f1_score 0.8003239241092086\n",
      "test f1_score 0.7518918918918919\n",
      "CPU times: user 18.3 s, sys: 33.1 s, total: 51.5 s\n",
      "Wall time: 51.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "nick = 'LogisticRegression full'\n",
    "f1_train, f1_test = commit_result(nick, y_train, y_pred_train, y_test, y_pred_test)\n",
    "result_final.append({\n",
    "    'nick':nick, 'train_size':X_train.shape[0], 'test_size':X_test.shape[0],\n",
    "    'f1_train':f1_train, 'f1_test':f1_test}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression full upsamling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего: 257926, токсичных 128963 (50.0%), не токсичных 128963\n"
     ]
    }
   ],
   "source": [
    "data_train_upsampled = do_upsampling(data_train_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы train: (257926, 32483) test: (15958, 32483)\n",
      "CPU times: user 30.8 s, sys: 0 ns, total: 30.8 s\n",
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "(X_train, X_test) = create_tf_idf(data_train_upsampled, data_valid)\n",
    "\n",
    "y_train = data_train_upsampled['toxic']\n",
    "y_test = data_valid['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression full upsampling\n",
      "train f1_score 0.9635815409799358\n",
      "test f1_score 0.756711873789095\n",
      "CPU times: user 22.9 s, sys: 32.9 s, total: 55.7 s\n",
      "Wall time: 55.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "nick = 'LogisticRegression full upsampling'\n",
    "f1_train, f1_test = commit_result(nick, y_train, y_pred_train, y_test, y_pred_test)\n",
    "result_final.append({\n",
    "    'nick':nick, 'train_size':X_train.shape[0], 'test_size':X_test.shape[0],\n",
    "    'f1_train':f1_train, 'f1_test':f1_test}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression full spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spacy = pd.read_csv('toxic_comments_lemmatized2.csv')[['lemm_text', 'toxic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего: 159571, токсичных 16225 (10.17%), не токсичных 143346\n"
     ]
    }
   ],
   "source": [
    "print_class_balance(data_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spacy_train_full, data_spacy_valid = train_test_split(\n",
    "    data_spacy, test_size = 0.1, random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы train: (143613, 27657) test: (15958, 27657)\n",
      "CPU times: user 21.3 s, sys: 0 ns, total: 21.3 s\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "(X_train, X_test) = create_tf_idf(data_spacy_train_full, data_spacy_valid)\n",
    "\n",
    "y_train = data_spacy_train_full['toxic']\n",
    "y_test = data_spacy_valid['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression full spacy\n",
      "train f1_score 0.8067168298422475\n",
      "test f1_score 0.7469421038325632\n",
      "CPU times: user 16.3 s, sys: 26.7 s, total: 43 s\n",
      "Wall time: 43.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "nick = 'LogisticRegression full spacy'\n",
    "f1_train, f1_test = commit_result(nick, y_train, y_pred_train, y_test, y_pred_test)\n",
    "result_final.append({\n",
    "    'nick':nick, 'train_size':X_train.shape[0], 'test_size':X_test.shape[0],\n",
    "    'f1_train':f1_train, 'f1_test':f1_test}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression full balanced\n",
      "f1_train 0.9264588050862219\n",
      "f1_test 0.6862213458220361\n",
      "train_size 29300\n",
      "test_size 15958\n",
      "\n",
      "LogisticRegression full\n",
      "f1_train 0.8003239241092086\n",
      "f1_test 0.7518918918918919\n",
      "train_size 143613\n",
      "test_size 15958\n",
      "\n",
      "LogisticRegression full upsampling\n",
      "f1_train 0.9635815409799358\n",
      "f1_test 0.756711873789095\n",
      "train_size 257926\n",
      "test_size 15958\n",
      "\n",
      "LogisticRegression full spacy\n",
      "f1_train 0.8067168298422475\n",
      "f1_test 0.7469421038325632\n",
      "train_size 143613\n",
      "test_size 15958\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in result_final:\n",
    "    print(row['nick'])\n",
    "    print('f1_train', row['f1_train'])\n",
    "    print('f1_test', row['f1_test'])\n",
    "    print('train_size', row['train_size'])\n",
    "    print('test_size', row['test_size'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В основном была борьба с Dead kernel, чем с задачей. Но результат 0.75 достигнут! =)\n",
    "\n",
    "### Борьба с Dead kernel\n",
    "**Большая часть изменений в create_tf_idf(df_train, df_test)**<br>\n",
    "Вместо ```corpus_train = df_train['lemm_text'].values.astype('U')``` делаю ```corpus_train = df_train['lemm_text'].apply(lambda x: np.str_(x))```\n",
    "\n",
    "TfidfVectorizer использую с параметрами ```TfidfVectorizer(min_df=5, max_df=0.7, stop_words=stopwords)```\n",
    "\n",
    "\n",
    "**Лемматизация \\ стеммизация**<br>\n",
    "Датасет с преобразованным столбцом сохранил в файле, для использования загружаю только нужные стольбцы<br>\n",
    "```data = pd.read_csv('toxic_comments_lemmatized2.csv')[['lemm_text', 'toxic']]```\n",
    "\n",
    "### Результаты\n",
    "LogisticRegression full balanced\n",
    "* f1_train 0.9264588050862219\n",
    "* f1_test 0.6862213458220361\n",
    "* train_size 29300\n",
    "* test_size 15958\n",
    "\n",
    "LogisticRegression full\n",
    "* f1_train 0.8003239241092086\n",
    "* f1_test 0.7518918918918919\n",
    "* train_size 143613\n",
    "* test_size 15958\n",
    "\n",
    "LogisticRegression full upsampling\n",
    "* f1_train 0.9635815409799358\n",
    "* f1_test 0.756711873789095\n",
    "* train_size 257926\n",
    "* test_size 15958\n",
    "\n",
    "LogisticRegression full spacy\n",
    "* f1_train 0.8067168298422475\n",
    "* f1_test 0.7469421038325632\n",
    "* train_size 143613\n",
    "* test_size 15958\n",
    "\n",
    "### Итого\n",
    "* Везде кроме одного обучения использовал стеммер SnowballStemmer\n",
    "* Получается что размер и разнообразие датасета важнее баланса: *LogisticRegression full balanced vs LogisticRegression full*, думаю критическое значение имеет значения объем векторизованных представлений слов: TfidfVectorizer\n",
    "* SnowballStemmer показал лучшие результаты чем spacy при одинаковых размерах выборок и прочих параметрах, возможно я не умею его готовить.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
