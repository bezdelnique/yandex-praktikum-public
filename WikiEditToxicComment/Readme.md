# Описание проекта

## Условие задачи

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

## Используемые технологии и подходы
Решил задачу бинарной классификации.

* pandas
* sklearn
* nltk \ spacy
* re

## Комментарии по выполненному заданияю

Можно улучшить
* Можно восстановить данные для моделей датированых 1910 и 1000 годом. Нужно подтвердить гипотезу что записи с моделями автомобилей этих лет выппущены в 2010 и 2000 году соответственно
* PostalCode - хороший признак в который можно углубиться. От региона может зависить стоимость автомобиля, но приведение этого признака к пригодному для использования виду это отдельный проект
* Для восстановления признаков Model, Gearbox, FuelType, VehicleType, RegistrationYear можно обучить модель. Берем строки где не задан признак Model, обучаем модель на признаках Brand, Gearbox, FuelType, VehicleType, RegistrationYear.

По задаче в целом
* Датасет несбалансирован
* Использовал SnowballStemmer, хотя очень хотелось nltk wordnet
* Везде кроме одного обучения использовал стеммер SnowballStemmer
* Получается что размер и разнообразие датасета важнее баланса: LogisticRegression full balanced vs LogisticRegression full, думаю критическое значение имеет значения объем векторизованных представлений слов: TfidfVectorizer
* SnowballStemmer показал лучшие результаты чем spacy при одинаковых размерах выборок и прочих параметрах, возможно я не умею его готовить.

