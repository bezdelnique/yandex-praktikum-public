# Описание проекта

## Цель

Определять токсичные комментарии.

## Результат

Лучшая модель:
* f1_test 0.756711873789095

## Используемые технологии и подходы
Решил задачу бинарной классификации.

* pandas
* sklearn
* nltk \ spacy
* re

## Комментарии по выполненному заданияю

Можно улучшить
* Можно восстановить данные для моделей датированых 1910 и 1000 годом. Нужно подтвердить гипотезу что записи с моделями автомобилей этих лет выппущены в 2010 и 2000 году соответственно
* PostalCode - хороший признак в который можно углубиться. От региона может зависить стоимость автомобиля, но приведение этого признака к пригодному для использования виду это отдельный проект
* Для восстановления признаков Model, Gearbox, FuelType, VehicleType, RegistrationYear можно обучить модель. Берем строки где не задан признак Model, обучаем модель на признаках Brand, Gearbox, FuelType, VehicleType, RegistrationYear.

По задаче в целом
* Датасет несбалансирован
* Использовал SnowballStemmer, хотя очень хотелось nltk wordnet
* Везде кроме одного обучения использовал стеммер SnowballStemmer
* Получается что размер и разнообразие датасета важнее баланса: LogisticRegression full balanced vs LogisticRegression full, думаю критическое значение имеет значения объем векторизованных представлений слов: TfidfVectorizer
* SnowballStemmer показал лучшие результаты чем spacy при одинаковых размерах выборок и прочих параметрах, возможно я не умею его готовить.

